<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.6.0 by Michael Rose
  Copyright 2017 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>解决python读取文本数据中的encoding问题 - 计算传播网</title>




<meta name="description" content="在使用python读取一些数据的实际应用当中，我们总会遇到各各种各样的encoding的问题，一般会使用utf8，中文常用的是gb18030和gbk。有时候这种问题非常令人头痛，有没有一种终极的解决方案？采用二进制的方法就可以读取，然后需要将二进制的字符串进行相应的decode，并忽略出错的地方。">




<meta name="author" content="王成军">

<meta property="og:locale" content="en">
<meta property="og:site_name" content="计算传播网">
<meta property="og:title" content="解决python读取文本数据中的encoding问题">


  <link rel="canonical" href="https://socrateslab.github.io/forum/python/byte-decoding/">
  <meta property="og:url" content="https://socrateslab.github.io/forum/python/byte-decoding/">



  <meta property="og:description" content="在使用python读取一些数据的实际应用当中，我们总会遇到各各种各样的encoding的问题，一般会使用utf8，中文常用的是gb18030和gbk。有时候这种问题非常令人头痛，有没有一种终极的解决方案？采用二进制的方法就可以读取，然后需要将二进制的字符串进行相应的decode，并忽略出错的地方。">



  <meta name="twitter:site" content="@ChengJunWang">
  <meta name="twitter:title" content="解决python读取文本数据中的encoding问题">
  <meta name="twitter:description" content="在使用python读取一些数据的实际应用当中，我们总会遇到各各种各样的encoding的问题，一般会使用utf8，中文常用的是gb18030和gbk。有时候这种问题非常令人头痛，有没有一种终极的解决方案？采用二进制的方法就可以读取，然后需要将二进制的字符串进行相应的decode，并忽略出错的地方。">
  <meta name="twitter:url" content="https://socrateslab.github.io/python/byte-decoding/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://socrateslab.github.io/forum/assets/images/unsplash-gallery-image-2-th.jpg">
    
  

  
    <meta name="twitter:creator" content="@ChengJunWang">
  



  

  



  <meta property="og:image" content="https://socrateslab.github.io/forum/assets/images/unsplash-image-18.jpg">



  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-05-12T00:00:00+00:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Organization",
      "name" : "计算传播网",
      "url" : "https://socrateslab.github.io/forum",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://socrateslab.github.io/forum/feed.xml" type="application/atom+xml" rel="alternate" title="计算传播网 Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/forum/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->
<!--mathjax start-->
    <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         inlineMath: [ ['$','$'], ["\\(","\\)"] ],
         processEscapes: true
       },
      TeX: {
         equationNumbers: { autoNumber: "AMS" }
      }
     });
    </script>
    <script type="text/javascript"
                src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <!--mathjax end-->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="https://socrateslab.github.io/forum/">计算传播网</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item"><a href="https://socrateslab.github.io/forum/about/">关于</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://socrateslab.github.io/forum/year-archive/">文章</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://socrateslab.github.io/forum/authors/">作者</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://socrateslab.github.io">中心</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://computational-communication.com/wiki/">百科</a></li>
          
        </ul>
        <button><div class="navicon"></div></button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    
  











<div class="page__hero--overlay"
  style="background-color: #000; background-image: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url('https://socrateslab.github.io/forum/assets/images/unsplash-image-18.jpg');"
>
  
    <div class="wrapper">
      <h1 class="page__title" itemprop="headline">
        
          解决python读取文本数据中的encoding问题

        
      </h1>
      
        <p class="page__lead">在使用python读取一些数据的实际应用当中，我们总会遇到各各种各样的encoding的问题，一般会使用utf8，中文常用的是gb18030和gbk。有时候这种问题非常令人头痛，有没有一种终极的解决方案？采用二进制的方法就可以读取，然后需要将二进制的字符串进行相应的decode，并忽略出错的地方。
</p>
      
      
      
    </div>
  
  
    <span class="page__hero-caption">Photo credit: <a href="https://unsplash.com"><strong>Unsplash</strong></a>
</span>
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="https://socrateslab.github.io/forum/assets/images/author/chengjun.jpg" class="author__avatar" alt="王成军" itemprop="image">
      
    </div>
  

  <div class="author__content">
    <h3 class="author__name" itemprop="name">王成军</h3>
    
      <p class="author__bio" itemprop="description">
        Follow your logic！
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        <li>
          <a href="https://chengjunwang.com/" itemprop="url">
            <i class="fa fa-fw fa-chain" aria-hidden="true"></i> Website
          </a>
        </li>
      

      
        <li>
          <a href="mailto:">
            <meta itemprop="email" content="" />
            <i class="fa fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/ChengJunWang" itemprop="sameAs">
            <i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      
        <li>
          <a href="https://plus.google.com/+" itemprop="sameAs">
            <i class="fa fa-fw fa-google-plus-square" aria-hidden="true"></i> Google+
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fa fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="解决python读取文本数据中的encoding问题">
    <meta itemprop="description" content="在使用python读取一些数据的实际应用当中，我们总会遇到各各种各样的encoding的问题，一般会使用utf8，中文常用的是gb18030和gbk。有时候这种问题非常令人头痛，有没有一种终极的解决方案？采用二进制的方法就可以读取，然后需要将二进制的字符串进行相应的decode，并忽略出错的地方。">
    <meta itemprop="datePublished" content="May 12, 2017">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        <p>在使用python读取一些数据的实际应用当中，我们总会遇到各各种各样的encoding的问题，一般会使用utf8，中文常用的是gb18030和gbk。有时候这种问题非常令人头痛，有没有一种终极的解决方案？采用二进制的方法就可以读取，然后需要将二进制的字符串进行相应的decode，并忽略出错的地方。</p>

<p>这种解决方案的一个案例见<a href="http://stackoverflow.com/questions/38728366/pandas-cannot-load-data-csv-encoding-mystery">这里</a><sup id="fnref:weiboscope" role="doc-noteref"><a href="#fn:weiboscope" class="footnote" rel="footnote">1</a></sup>。Kristof评论说：</p>

<blockquote>
  <p>It seems that there’s something very wrong with the input file. There are encoding errors throughout. One thing you could do, is to read the CSV file as a binary, decode the binary string and replace the erroneous characters.</p>
</blockquote>

<p>在复旦大学上课的过程中，葆华老师发现一个微信公众号数据没有办法很好地使用pandas读取，我们尝试了各种encoding的策略都没有成功。</p>

<p>这个文本文件在mac环境中可以采用mac自带的文本编辑软件可以打开，但使用sublime却无法打开，采用visual studio code编辑器指定gbk或者gb18030都可以正确打开，这使得我意识到这个数据本身就是一个gb18030编码的数据，只是因为存在各种不规则的的东西使得解码变得很苦难。</p>

<p>借助于以上解决方法，采用以下python代码就可以有效地解决问题。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">in_filename</span> <span class="o">=</span> <span class="s">'/Users/chengjun/github/cjc/data/try.txt'</span>
<span class="n">out_filename</span> <span class="o">=</span> <span class="s">'/Users/chengjun/github/cjc/data/try4.txt'</span>

<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="c1"># chunksize = 100*1024*1024 # read 100MB at a time
</span>
<span class="c1"># Decode with UTF-8 and replace errors with "?"
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">in_filename</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">in_file</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">out_filename</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">out_file</span><span class="p">:</span>
        <span class="c1"># for byte_fragment in iter(partial(in_file.read, chunksize), b''):
</span>        <span class="k">for</span> <span class="n">byte_fragment</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">in_file</span><span class="p">.</span><span class="n">read</span><span class="p">),</span> <span class="sa">b</span><span class="s">''</span><span class="p">):</span>
            <span class="n">byte_file</span> <span class="o">=</span> <span class="n">byte_fragment</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'gb18030'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="n">out_file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">byte_file</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf8'</span><span class="p">))</span>

<span class="c1"># Now read the repaired file into a dataframe
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">out_filename</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">';'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>公众号昵称</th>
      <th>微信号</th>
      <th>公众号类别</th>
      <th>作者</th>
      <th>发布位置</th>
      <th>是否原创</th>
      <th>标题</th>
      <th>文章链接</th>
      <th>摘要</th>
      <th>正文</th>
      <th>...</th>
      <th>更新时间</th>
      <th>Unnamed: 19</th>
      <th>Unnamed: 20</th>
      <th>Unnamed: 21</th>
      <th>Unnamed: 22</th>
      <th>Unnamed: 23</th>
      <th>Unnamed: 24</th>
      <th>Unnamed: 25</th>
      <th>Unnamed: 26</th>
      <th>Unnamed: 27</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>中国政府网</td>
      <td>zhengfu</td>
      <td>政务</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>李克强“盯”住农民工欠薪：决不能让他们背井离乡流汗再流泪</td>
      <td>http://mp.weixin.qq.com/s?__biz=MzA4MDA0MzcwMA...</td>
      <td>“农民工在外打工非常不易，决不能让他们背井离乡流汗再流泪！”李克强斩钉截铁地说。</td>
      <td>丨来源：新京报新媒体鲁甸地震受灾群众甘永荣的一句话，让李克强总理的表情立刻凝重起来。“你打工...</td>
      <td>...</td>
      <td>2017-01-27 11:32:16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>中国政府网</td>
      <td>zhengfu</td>
      <td>政务</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>总理对话农民工，问过哪些问题？</td>
      <td>http://mp.weixin.qq.com/s?__biz=MzA4MDA0MzcwMA...</td>
      <td>总理考察活动时和农民工聊过什么话题？说过哪些话？中国政府网为你一一梳理。</td>
      <td>总理考察活动时和农民工聊过什么话题？说过哪些话？中国政府网为你一一梳理。 总理和农民工聊过这...</td>
      <td>...</td>
      <td>2017-02-02 11:32:48</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>中国政府网</td>
      <td>zhengfu</td>
      <td>政务</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>云南考察 | 李克强：农民工欠薪问题必须反复抓、抓到底</td>
      <td>http://mp.weixin.qq.com/s?__biz=MzA4MDA0MzcwMA...</td>
      <td>李克强23日考察灾后重建的云南鲁甸，再三问询围拢人群，有没有没领到工资的农民工？现场陆续有人...</td>
      <td>李克强春节前重回鲁甸李克强23日重回云南鲁甸考察灾后重建。看到这里焕然一新的面貌，总理说，你...</td>
      <td>...</td>
      <td>2017-01-26 13:16:40</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>中国政府网</td>
      <td>zhengfu</td>
      <td>政务</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>李克强：决不能让农民工的辛勤付出得不到回报</td>
      <td>http://mp.weixin.qq.com/s?__biz=MzA4MDA0MzcwMA...</td>
      <td>李克强：决不能让农民工的辛勤付出得不到回报</td>
      <td>2月3日，春节后的首个工作日，国务院召开常务会议，其中议题之一便是部署建立解决农民工工资拖欠...</td>
      <td>...</td>
      <td>2017-02-07 11:38:30</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>中国政府网</td>
      <td>zhengfu</td>
      <td>政务</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>48小时!总理帮震区农民工“讨”回欠薪</td>
      <td>http://mp.weixin.qq.com/s?__biz=MzA4MDA0MzcwMA...</td>
      <td>48小时！总理帮震区农民工“讨”回欠薪</td>
      <td>丨来源：新京报新媒体1月25日早上8点半，甘永荣的银行卡里打进来5.8万元。这是李克强总理帮...</td>
      <td>...</td>
      <td>2017-01-29 11:57:45</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 28 columns</p>
</div>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:weiboscope" role="doc-endnote">
      <p>值得注意的是这里也是中文的文本，来自于香港大学抓取的新浪微博的数据。 <a href="#fnref:weiboscope" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://socrateslab.github.io/forum/tags/#encoding" class="page__taxonomy-item" rel="tag">encoding</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://socrateslab.github.io/forum/categories/#python" class="page__taxonomy-item" rel="tag">python</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Updated:</strong> <time datetime="2017-05-12T00:00:00+00:00">May 12, 2017</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

<!-- needsharebutton Javascript file -->
<script src="/assets/js/needsharebutton.min.js"></script>
<!-- needsharebutton CSS file -->
<link href="/assets/css/needsharebutton.min.css" rel="stylesheet" />

<button  class="btn btn-default need-share-button">Share</button>
  <a href="https://twitter.com/intent/tweet?via=ChengJunWang&text=%E8%A7%A3%E5%86%B3python%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84encoding%E9%97%AE%E9%A2%98%20https%3A%2F%2Fsocrateslab.github.io%2Fforum%2Fpython%2Fbyte-decoding%2F" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fsocrateslab.github.io%2Fforum%2Fpython%2Fbyte-decoding%2F" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=https%3A%2F%2Fsocrateslab.github.io%2Fforum%2Fpython%2Fbyte-decoding%2F" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fsocrateslab.github.io%2Fforum%2Fpython%2Fbyte-decoding%2F" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="https://socrateslab.github.io/forum/%E6%95%B0%E6%8D%AE%E6%96%B0%E9%97%BB/dj2017/" class="pagination--pager" title="2017数据新闻比赛
">Previous</a>
    
    
      <a href="https://socrateslab.github.io/forum/css/cfp-ajoc/" class="pagination--pager" title="Call for Papers：A Special Issue of Asian Journal of Communication
">Next</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
    
        <h4 class="page__comments-title">Leave a Comment</h4>
        <section id="disqus_thread">
          <a href="#" onclick="disqus();return false;">Show Comments</a>
        </section>
      
</div>

    

    
  </article>


  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/unsplash-gallery-image-4-th.jpg"
          
          alt="">
      </div>
    
    
    <h2 class="archive__item-title" itemprop="headline">
      <a href="/forum/thresholdbook/" rel="permalink">王成军副教授专著《跨越网络的门槛》出版
</a>
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">‘信息扩散作为一种普遍存在的现象，在人类生活中扮演着重要角色。伴随着Web2.0的兴起，信息共享网站（Information Sharing Website，ISW）已经成为互联网信息扩散的新平台。信息共享网站通常以社交网络服务（Social Networking Service，SNS）、信息聚合器（infor...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/500x300.png"
          
          alt="">
      </div>
    
    
    <h2 class="archive__item-title" itemprop="headline">
      <a href="/forum/ugly-duckling/" rel="permalink">寻找真、假新闻中的“丑小鸭”：使用窥视策略预测新闻扩散规模和真实性
</a>
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">信息扩散中存在着一些“丑小鸭”类型的信息。“丑小鸭”类型的信息初始阶段就与众不同，一经转发，便可成为网络中的流行信息。
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/unsplash-gallery-image-2-th.jpg"
          
          alt="">
      </div>
    
    
    <h2 class="archive__item-title" itemprop="headline">
      <a href="/forum/douban-group/" rel="permalink">计算传播网迁移至豆瓣小组
</a>
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">为了方便维护和更新，计算传播网正式迁移至豆瓣小组。链接为：https://www.douban.com/group/webmining/
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/unsplash-gallery-image-2-th.jpg"
          
          alt="">
      </div>
    
    
    <h2 class="archive__item-title" itemprop="headline">
      <a href="/forum/python/actual-entropy/" rel="permalink">思考真实熵
</a>
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">在Limits of Predictability in Human Mobility一文（Song, 2010, Science）当中，Song等人提出人类移动行为的可预测性问题。强调了采用香农熵或随机熵不能捕捉到移动位置的时间序列特点，主张采用一种真实熵(the actual entropy)的测量方式，表示...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->

        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="https://twitter.com/ChengJunWang"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
    
    
    
    
    
    <li><a href="https://socrateslab.github.io/forum/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 计算传播网. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/forum/assets/js/main.min.js"></script>




  
      <script type="text/javascript">
// Replace labnol with your disqus shortname
var disqus_shortname = 'computational-communication';
// Put the permalink of your web page / blog post
var disqus_url = "https://socrateslab.github.io/forum/python/byte-decoding/";
// Put the permalink of your web page / blog post
var disqus_identifier = "/python/byte-decoding";
var disqus_loaded = false;
// This is the function that will load Disqus comments on demand
function disqus() {
  if (!disqus_loaded)  {
    // This is to ensure that Disqus widget is loaded only once
    disqus_loaded = true;
    var e = document.createElement("script");
    e.type = "text/javascript";
    e.async = true;
    e.src = "//" + disqus_shortname + ".disqus.com/embed.js";
    (document.getElementsByTagName("head")[0] ||
     document.getElementsByTagName("body")[0])
    .appendChild(e);
  }
}
</script>
<!--


  <script type="text/javascript">
  	/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  	var disqus_shortname = 'computational-communication';
  	/* * * DON'T EDIT BELOW THIS LINE * * */
  	(function() {
  		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  	})();
  	/* * * DON'T EDIT BELOW THIS LINE * * */
  	(function () {
  		var s = document.createElement('script'); s.async = true;
  		s.type = 'text/javascript';
  		s.src = '//' + disqus_shortname + '.disqus.com/count.js';
  		(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
  	}());
  </script>

  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <script>
    var disqus_config = function () {
      this.page.url = "https://socrateslab.github.io/forum/python/byte-decoding/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/python/byte-decoding"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://computational-communication.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

-->

    



  </body>
</html>
