I"@ó<p><strong>Author</strong>: David Masad</p>

<p>Source: <a href="http://davidmasad.com/blog/ergms-from-scratch/">http://davidmasad.com/blog/ergms-from-scratch/</a></p>

<p>Exponential random graph models (ERGMs) are statistical models for explaining the structure of social and other networks (also called graphs). If we have a network, and some hypotheses about the factors that make it looks the way it does, an ERGM is meant to tell us how big a role (if any) these factors actually play.</p>

<p>I think of it as a regression model: we have several independent variables we think determine the dependent variable, and the model estimates the size and significance of the effect of each.</p>

<p>For someone like me who works a lot with networks, ERGMs can be a very powerful tool. There is even an excellent R package called, appropriately enough, ergm, that makes estimating ERGMs just about as easy as specifying a regression formula.</p>

<p>I‚Äôve always felt a bit nervous about using them, though, because I didn‚Äôt feel confident I really understood how they worked, and how they were being estimated.</p>

<h1 id="toy-ergm-from-scratch">Toy ERGM from Scratch</h1>

<p>To help with that, I decided I needed to implement a simple toy ERGM from scratch. It didn‚Äôt need to be fast, or really applicable at all. The most important thing was to take the methodology apart and put it back together again.</p>

<p>In this post, I‚Äôm going to walk through my implementation of a highly simplified ERGM estimation, using Python and the NetworkX package. I‚Äôm hoping that it will help others with similar questions, and that people who know more than I do will point out anything I‚Äôm getting wrong.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
</code></pre></div></div>

<h1 id="graph-probabilities">Graph probabilities</h1>

<p>The basic idea of ERGMs is to define a probability distribution over all possible graphs of a given number of nodes, where the probability of each graph is proportional to some of its network statistics. In this post, the statistics I‚Äôll use throughout are the edge count and the number of triangles, but any network statistics will do. If edge count and triangles have coefficients a and b, then the probability of observing a particular graph G is:</p>

\[Pr(G)‚àùa‚àóedges(G)+b‚àótriangles(G)\]

<p>or more specifically:</p>

\[Pr(G)‚àùe^{a‚àóedges(G)+b‚àótriangles(G)}\]

<p>(hence the exponential).</p>

<p>Think of this as the ‚Äòweight‚Äô we put on a particular network. In Python, this looks like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_weight</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">tri_coeff</span><span class="p">):</span>
    <span class="s">'''
    Compute the probability weight on graph G
    '''</span>
    <span class="n">edge_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="n">edges</span><span class="p">())</span>
    <span class="n">triangles</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">nx</span><span class="p">.</span><span class="n">triangles</span><span class="p">(</span><span class="n">G</span><span class="p">).</span><span class="n">values</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">edge_count</span> <span class="o">*</span> <span class="n">edge_coeff</span> <span class="o">+</span> <span class="n">triangles</span> <span class="o">*</span> <span class="n">tri_coeff</span><span class="p">)</span>
</code></pre></div></div>

<p>To turn that weight into a probability, we need to normalize it by the weights of all other possible networks. Mathematically:</p>

\[Pr(G)=\frac{exp(a‚àóedges(G)+b‚àótriangles(G))}{‚àë_{g‚ààG}exp(a‚àóedges(g)+b‚àótriangles(g))}\]

<p>Now we come to the first problem: calculating the denominator of that equation. There are many possible graphs. To take the simplest example, an undirected graph with 3 nodes has 8 possible configurations:</p>

<p><img src="https://socrateslab.github.io/handbook/assets/img2017/ergm0.png" alt="" /></p>

<p>There are 64 possible configurations for a 4-node graph, and the number of possible configurations grows mind-bogglingly quickly after that. Most of the time, we simply can‚Äôt calculate the weights for all possible graphs. Instead, we need some sort of approximation.</p>

<p>We could just generate some large number of random graphs, and use that ‚Äì but we have no way of knowing how representative they are of the actual distribution. We need a way to generate a sample that we think covers the most probable area of the distribution. In terms of the equation above, we want to sample heavily from networks where the weights are large, and less where the weights are small, so that the sum of the weights of the sample gets as close as possible to the actual total weight. Which brings us to the next step:</p>

<h1 id="markov-chain-monte-carlo">Markov Chain Monte Carlo</h1>

<p>Markov Chain Monte Carlo (MCMC) actually refers a broad class of techniques for generating samples from complicated distributions. For our purposes, it means exploring the space of possible networks, moving toward the ones which are more likely given the distribution coefficients.</p>

<p>We‚Äôll implement a simple version of the Metropolis-Hastings algorithm. We start with some network, and randomly add or subtract an edge.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">permute_graph</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
    <span class="s">'''
    Return a new graph with an edge randomly added or subtracted from G
    '''</span>
    <span class="n">G1</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">density</span><span class="p">(</span><span class="n">G1</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">r</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">d</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Add an edge
</span>        <span class="n">nodes</span> <span class="o">=</span> <span class="n">G</span><span class="p">.</span><span class="n">nodes</span><span class="p">()</span>
        <span class="n">n1</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
        <span class="n">n2</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
        <span class="n">G1</span><span class="p">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Remove an edge
</span>        <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">G1</span><span class="p">.</span><span class="n">edges</span><span class="p">())</span>
        <span class="n">G1</span><span class="p">.</span><span class="n">remove_edge</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">G1</span>

</code></pre></div></div>

<p>After the change, we check the weight on this new network.</p>

<ul>
  <li>If it‚Äôs greater than the previous network‚Äôs weight (that is, it‚Äôs more probable under this distribution), we accept it and add it to our sample; it is also our new ‚Äòcurrent‚Äô network.</li>
  <li>Otherwise, we might still accept it, deciding randomly based on the ratio between the new and old weights.</li>
</ul>

<p>We repeat this many times, until we decide we have enough samples. The starting network can be any graph ‚Äì I found that a random network worked well for my relatively small sample sizes, but we can also use the observed network itself, or a completely empty one. In theory, it shouldn‚Äôt matter after enough iterations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mcmc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">triangle_coeff</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="s">'''
    Use MCMC to generate a sample of networks from an ERG distribution.

    Args:
        G: The observed network, to seed the graph with
        edge_coeff: The coefficient on the number of edges
        triangle_coeff: The coefficient on number of triangles
        n: The number of samples to generate
    Returns:
        A list of graph objects
    '''</span>

    <span class="n">v</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="c1"># number of nodes in G
</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">density</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="c1"># Probability of a random edge existing
</span>    <span class="n">current_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">erdos_renyi_graph</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># Random graph
</span>    <span class="n">current_w</span> <span class="o">=</span> <span class="n">compute_weight</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">triangle_coeff</span><span class="p">)</span>
    <span class="n">graphs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">graphs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="n">new_graph</span> <span class="o">=</span> <span class="n">permute_graph</span><span class="p">(</span><span class="n">current_graph</span><span class="p">)</span>
        <span class="n">new_w</span> <span class="o">=</span> <span class="n">compute_weight</span><span class="p">(</span><span class="n">new_graph</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">triangle_coeff</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_w</span> <span class="o">&gt;</span> <span class="n">current_w</span> <span class="ow">or</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">new_w</span><span class="o">/</span><span class="n">current_w</span><span class="p">):</span>
            <span class="n">graphs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_graph</span><span class="p">)</span>
            <span class="n">current_w</span> <span class="o">=</span> <span class="n">new_w</span>
    <span class="k">return</span> <span class="n">graphs</span>
</code></pre></div></div>

<p>So this code lets us generate a sample of networks from an exponential random graph distribution when we know the coefficients.</p>

<p>However, what we really want to do is find the coefficients. To do this, we want to look for the coefficients that describe an ERG distribution that makes the observed graph as likely as possible.</p>

<h1 id="fitting-the-model">Fitting the model</h1>

<p>The first thing we need to do is calculate the probability of observing any given graph, which means summing the weights of all the graphs in a sample:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_weights</span><span class="p">(</span><span class="n">graphs</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">tri_coeff</span><span class="p">):</span>
    <span class="s">'''
    Sum the probability weights on every graph in graphs
    '''</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">graphs</span><span class="p">:</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">compute_weight</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">tri_coeff</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total</span>
</code></pre></div></div>

<p>With this, we can calculate the probability of a given graph by dividing its weight by the sum of all weights from the sample.</p>

<p>Next, we can use our favorite optimization technique to hunt through the space of possible edge and triangle coefficients.</p>

<p>Instead of changing the network, we‚Äôll randomly change the parameters, and use our MCMC function to estimate the probability of getting the observed network at those parameter values.</p>

<p>One simple way to do it uses a similar Metropolis-Hastings approach to the one we used above, with one tweak: early on, we want to try larger jumps around the parameter space; as we get further along, and hopefully closer to the ‚Äòbest‚Äô value, the jumps should get smaller and smaller. There‚Äôs not really a right way to tweak the jump size</p>

<p>Here‚Äôs the code I came up with to do it:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fit_ergm</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">coeff_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">graph_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="s">'''
    Use MCMC to sample possible coefficients, and return the best fits.

    Args:
        G: The observed graph to fit
        coeff_samples: The number of coefficient combinations to sample
        graph_samples: The number of graphs to sample for each set of coeffs
        return_all: If True, return all sampled values. Otherwise, only best.
    Returns:
        If return_all=False, returns a tuple of values,
            (best_edge_coeff, best_triangle_coeff, best_p)
        where p is the estimated probability of observing the graph G with
        the fitted parameters.

        Otherwise, return a tuple of lists:
            (edge_coeffs, triangle_coeffs, probs)
    '''</span>
    <span class="n">edge_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">triangle_coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">coeff_samples</span><span class="p">:</span>
        <span class="c1"># Make the jump size larger early on, and smaller toward the end
</span>        <span class="n">w</span> <span class="o">=</span> <span class="n">coeff_samples</span><span class="o">/</span><span class="mf">50.0</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">w</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>
        <span class="c1"># Pick new coefficients to try:
</span>        <span class="n">edge_coeff</span> <span class="o">=</span> <span class="n">edge_coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>  <span class="n">random</span><span class="p">.</span><span class="n">normalvariate</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">triangle_coeff</span> <span class="o">=</span> <span class="n">triangle_coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">random</span><span class="p">.</span><span class="n">normalvariate</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="c1"># Check how likely the observed graph is under this distribution:
</span>        <span class="n">graphs</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">triangle_coeff</span><span class="p">,</span> <span class="n">graph_samples</span><span class="p">)</span>
        <span class="n">sum_weight</span> <span class="o">=</span> <span class="n">sum_weights</span><span class="p">(</span><span class="n">graphs</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">triangle_coeff</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">compute_weight</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">edge_coeff</span><span class="p">,</span> <span class="n">triangle_coeff</span><span class="p">)</span> <span class="o">/</span> <span class="n">sum_weight</span>
        <span class="c1"># Decide whether to accept the jump:
</span>        <span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">probs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">or</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">probs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">edge_coeffs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge_coeff</span><span class="p">)</span>
            <span class="n">triangle_coeffs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">triangle_coeff</span><span class="p">)</span>
            <span class="n">probs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">edge_coeffs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge_coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">triangle_coeffs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">triangle_coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">probs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># Return either the best values, or all of them:
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
        <span class="n">best_p</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">best_edge_coeff</span> <span class="o">=</span> <span class="n">edge_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">best_triangle_coeff</span> <span class="o">=</span> <span class="n">triangle_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">best_edge_coeff</span><span class="p">,</span> <span class="n">best_triangle_coeff</span><span class="p">,</span> <span class="n">best_p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">edge_coeffs</span><span class="p">,</span> <span class="n">triangle_coeffs</span><span class="p">,</span> <span class="n">probs</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="example-application">Example application</h1>

<p>Now the real test ‚Äì fitting the ERGM to an actual network. The canonical example is the Florentine marriage network, which is included in NetworkX.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">florentine_families_graph</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nx</span><span class="p">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://socrateslab.github.io/handbook/assets//img2017/ergm1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>
<span class="n">graphs</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 loop, best of 3: 6.79 s per loop
</code></pre></div></div>

<p>I fit the ERGM with 100 coefficient iterations and 10,000 random networks for each candidate distribution. I also have it return the full series of steps. Note: this part takes a while.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">timeit</span>
<span class="n">edge_coeffs</span><span class="p">,</span> <span class="n">triangle_coeffs</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">fit_ergm</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The slowest run took 25.50 times longer than the fastest. This could mean that an intermediate result is being cached.
10 loops, best of 3: 199 ms per loop
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">edge_coeffs</span><span class="p">,</span> <span class="n">triangle_coeffs</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">fit_ergm</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="k">print</span> <span class="nb">max</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="k">print</span> <span class="n">edge_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="k">print</span> <span class="n">triangle_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.59541550664
0.445701809562
-0.492293584485
</code></pre></div></div>

<p>Once it‚Äôs done (about 20 minutes later, for me), we can find the values it converged to. For me, they were:</p>

<p>Edge coefficient: -1.667</p>

<p>Triangle coefficient: -0.258</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>==========================
Summary of model fit
==========================

Formula:   flomarriage ~ edges + triangles

Iterations:  20

Monte Carlo MLE Results:
         Estimate Std. Error MCMC % p-value    
edges     -1.6773     0.3499      0  &lt;1e-04 ***
triangle   0.1574     0.5831      0   0.788    
---
Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1
Not too far off! The edge coefficient is very close; the triangle coefficient is not too far off, and in any case isn't statistically significant.
</code></pre></div></div>

<p>One problem I discovered is that I obtained some estimated probabilities for the observed network that were greater than 1. This means that the network MCMC was sampling far away from the observed network, so that the weight on the observed network was greater than the sum of weights on all the sampled networks. This isn‚Äôt a great outcome, though it still does tell us something about how likely the observed network is under that distribution. Increasing the network sample size might help make this problem go away, as would improving the Markov chain procedure (e.g. with more permutation between networks).</p>

<p>We can do a few more diagnostics on the results. For example, the trace of the value of the coefficients at each iteration is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">p1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">edge_coeffs</span><span class="p">)</span>
<span class="n">p2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">triangle_coeffs</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Coefficient value"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Iteration"</span><span class="p">)</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="s">"Edge coefficient"</span><span class="p">,</span> <span class="s">"Triangle coefficient"</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="https://socrateslab.github.io/handbook/assets//img2017/ergm2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weighted_edge_coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">edge_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="k">print</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">weighted_edge_coeffs</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.297715535504
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weighted_tri_coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">triangle_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="k">print</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">weighted_tri_coeffs</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-0.481915973737
</code></pre></div></div>

<p>We can also see the distribution of possible coefficients, by making a histogram weighted by the likelihood we observed for each value. (To deal with the likelihoods estimated at greater than 1, I actually weight each coefficient value by the log of the estimated likelihood).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">edge_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">weights</span><span class="o">=-</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Edge coefficient"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Coefficient value"</span><span class="p">)</span>

<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">triangle_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">weights</span><span class="o">=-</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Triangle coefficient"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Coefficient value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://socrateslab.github.io/handbook/assets/img2017/ergm3.png" alt="png" /></p>

<p>This shows that the bulk of the weight on the edge coefficient is between -1 and -2, while the triangle coefficient is much more evenly distributed on both sides of 0. Using a distribution like this, we can statistically test whether the coefficients are significantly different from 0, estimate the standard error, and do various other statistical tests and operations I won‚Äôt cover here.</p>

<p>And that‚Äôs it! We have a slow, simplistic but apparently somewhat-working ERGM model fitter, built up from scratch.</p>

<p>If you want to learn how to actually do ERGM analysis in R , Benjamin Lind has a great <a href="http://badhessian.org/2012/09/lessons-on-exponential-random-graph-modeling-from-greys-anatomy-hook-ups/">hands-on tutorial</a> over at Bad Hessian on using ERGMs to model the hookup network on the TV show Grey‚Äôs Anatomy.</p>

<p>The paper <a href="http://www.jstatsoft.org/v24/i03/paper">introducing the ergm package</a> by Hunter et al., the package developers, is a great guide</p>

<p>as is the (paywalled) <a href="http://www.sciencedirect.com/science/article/pii/S0378873306000372">An introduction to exponential random graph (p*) models for social networks</a> by Robins et al.</p>

<p><a href="http://www.cmu.edu/joss/content/articles/volume3/Snijders.pdf">Markov Chain Monte Carlo Estimation of Exponential Random Graph Models</a> by Tom Snijders goes into more detail on estimation methodology, and includes an appendix with a much better estimation algorithm, which I may try to implement in the future.</p>
:ET